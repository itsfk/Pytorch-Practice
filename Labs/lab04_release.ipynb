{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab04_release.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "871004aa13eb4b05a56bcde07a5663bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ab359fda44de4eafa3108db68d21df26",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_342e858ed43344519db30b493181e2d9",
              "IPY_MODEL_88a0cba8150845d0a9681a592b6d5ee2"
            ]
          }
        },
        "ab359fda44de4eafa3108db68d21df26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "342e858ed43344519db30b493181e2d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_be8559d8a9f6495ea025de683beda94f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_948730672fc24d369e28b4321c761fa7"
          }
        },
        "88a0cba8150845d0a9681a592b6d5ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f966fbf0b2894f31a075b6eab7f0447e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10/10 [03:32&lt;00:00, 21.27s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c3bc724496f469eabb51889853c4905"
          }
        },
        "be8559d8a9f6495ea025de683beda94f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "948730672fc24d369e28b4321c761fa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f966fbf0b2894f31a075b6eab7f0447e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c3bc724496f469eabb51889853c4905": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f352653ec508406a80c262f42ea05e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_da9934e121a248f5933778b6dd0a31d9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7d0f6952c2014e73a1a855acad2ba0ee",
              "IPY_MODEL_ac4a02d7ab0c4bc0a6f9399ac5c55b70"
            ]
          }
        },
        "da9934e121a248f5933778b6dd0a31d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d0f6952c2014e73a1a855acad2ba0ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_525e7fe7282747a998fa09cce6cb6f22",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb78c41f23cd4e6e88da4d86b784a547"
          }
        },
        "ac4a02d7ab0c4bc0a6f9399ac5c55b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a7c49cd973f54f5aae969fd86d9889d3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/1000 [01:58&lt;00:00,  8.47it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3b40567def634a4d83cbcd46f292d6d5"
          }
        },
        "525e7fe7282747a998fa09cce6cb6f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb78c41f23cd4e6e88da4d86b784a547": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7c49cd973f54f5aae969fd86d9889d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3b40567def634a4d83cbcd46f292d6d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lAszzUtMGKS"
      },
      "source": [
        "# Lab 4 - Debugging Neural Networks\n",
        "\n",
        "In this notebook we'll take a look at some common issues encountered when building and training neural networks. As a lot of the code has been written for you, work slowly through the notebook, reading along the way - there are some important information!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdocimy3CAuL"
      },
      "source": [
        "## Data Normalisation\n",
        "\n",
        "In this exercise we'll take a look at a form of [normalisation](https://en.wikipedia.org/wiki/Normalization_(statistics)) and how it can aide the training of neural networks (and other optimisation techniques, for that matter). As mentioned in the lectures, neural networks are most stable when the inputs and outputs have values near zero, with a standard deviation of approximately 1. Let's see what this looks like in practice.\n",
        "\n",
        "We will demonstrate the importance of normalization using an interesting forecast prediction dataset. In this dataset we will use cartographic variables of small regions of forest (30m x 30m) to predict the type of forecast cover in each region. Example cover types include: spruce/fir (type 1), lodgepole pine (type 2), etc.\n",
        "\n",
        "You can get more information about the data from this link.\n",
        "https://archive.ics.uci.edu/ml/datasets/covertype\n",
        "\n",
        "There is also a kaggle competition for this dataset:\n",
        "https://www.kaggle.com/c/forest-cover-type-prediction/overview\n",
        "\n",
        "According to the kaggle competition the best team got an accuracy of 100% on the test set! \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLyNJBZIkkru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5449975-6d64-4319-da35-2205d5601f19"
      },
      "source": [
        "# Quickly set up our device\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    torch.cuda.set_device(device)\n",
        "print(\"Training on\", device)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK6ca8tVulaf"
      },
      "source": [
        "Here is the code we use to load the data into a pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGjSlxSFcYKy"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the data from csv file\n",
        "cover_type_df = pd.read_csv('https://github.com/zhenhe1/datasets/raw/5852941fa9cd21326d3f7277d971e46e48ea2714/covtype_dataset.zip')\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaSY9go5uso2"
      },
      "source": [
        "Lets take a look at the data using the next cell. Each row of the data contains the data for one small 30m x 30m region of the forest. You will notice the cartographic variables include things like elevation, aspect, slope, soil types etc. You will notice that the soil type values are much smaller than elevation, aspect, hydrology measurements. This is a sign that normalization is needed. The reason is it will be hard for the neural network to balance taking really big numbers and really small numbers at the same time. This will cause a lot of skew in the distribution of neural network weights. In addition neural networks just want to take small number as input and mean of around zero. Lets first try to train a network without normalization and then add normalization and see what happens.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3lRrn6YcY4X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "3942f682-0899-442f-e615-3ea0c875c4fb"
      },
      "source": [
        "cover_type_df"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Elevation</th>\n",
              "      <th>Aspect</th>\n",
              "      <th>Slope</th>\n",
              "      <th>Horizontal_Distance_To_Hydrology</th>\n",
              "      <th>Vertical_Distance_To_Hydrology</th>\n",
              "      <th>Horizontal_Distance_To_Roadways</th>\n",
              "      <th>Hillshade_9am</th>\n",
              "      <th>Hillshade_Noon</th>\n",
              "      <th>Hillshade_3pm</th>\n",
              "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
              "      <th>Wilderness_Area1</th>\n",
              "      <th>Wilderness_Area2</th>\n",
              "      <th>Wilderness_Area3</th>\n",
              "      <th>Wilderness_Area4</th>\n",
              "      <th>Soil_Type1</th>\n",
              "      <th>Soil_Type2</th>\n",
              "      <th>Soil_Type3</th>\n",
              "      <th>Soil_Type4</th>\n",
              "      <th>Soil_Type5</th>\n",
              "      <th>Soil_Type6</th>\n",
              "      <th>Soil_Type7</th>\n",
              "      <th>Soil_Type8</th>\n",
              "      <th>Soil_Type9</th>\n",
              "      <th>Soil_Type10</th>\n",
              "      <th>Soil_Type11</th>\n",
              "      <th>Soil_Type12</th>\n",
              "      <th>Soil_Type13</th>\n",
              "      <th>Soil_Type14</th>\n",
              "      <th>Soil_Type15</th>\n",
              "      <th>Soil_Type16</th>\n",
              "      <th>Soil_Type17</th>\n",
              "      <th>Soil_Type18</th>\n",
              "      <th>Soil_Type19</th>\n",
              "      <th>Soil_Type20</th>\n",
              "      <th>Soil_Type21</th>\n",
              "      <th>Soil_Type22</th>\n",
              "      <th>Soil_Type23</th>\n",
              "      <th>Soil_Type24</th>\n",
              "      <th>Soil_Type25</th>\n",
              "      <th>Soil_Type26</th>\n",
              "      <th>Soil_Type27</th>\n",
              "      <th>Soil_Type28</th>\n",
              "      <th>Soil_Type29</th>\n",
              "      <th>Soil_Type30</th>\n",
              "      <th>Soil_Type31</th>\n",
              "      <th>Soil_Type32</th>\n",
              "      <th>Soil_Type33</th>\n",
              "      <th>Soil_Type34</th>\n",
              "      <th>Soil_Type35</th>\n",
              "      <th>Soil_Type36</th>\n",
              "      <th>Soil_Type37</th>\n",
              "      <th>Soil_Type38</th>\n",
              "      <th>Soil_Type39</th>\n",
              "      <th>Soil_Type40</th>\n",
              "      <th>Cover_Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2596</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>221</td>\n",
              "      <td>232</td>\n",
              "      <td>148</td>\n",
              "      <td>6279</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2590</td>\n",
              "      <td>56</td>\n",
              "      <td>2</td>\n",
              "      <td>212</td>\n",
              "      <td>-6</td>\n",
              "      <td>390</td>\n",
              "      <td>220</td>\n",
              "      <td>235</td>\n",
              "      <td>151</td>\n",
              "      <td>6225</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2804</td>\n",
              "      <td>139</td>\n",
              "      <td>9</td>\n",
              "      <td>268</td>\n",
              "      <td>65</td>\n",
              "      <td>3180</td>\n",
              "      <td>234</td>\n",
              "      <td>238</td>\n",
              "      <td>135</td>\n",
              "      <td>6121</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2785</td>\n",
              "      <td>155</td>\n",
              "      <td>18</td>\n",
              "      <td>242</td>\n",
              "      <td>118</td>\n",
              "      <td>3090</td>\n",
              "      <td>238</td>\n",
              "      <td>238</td>\n",
              "      <td>122</td>\n",
              "      <td>6211</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2595</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>-1</td>\n",
              "      <td>391</td>\n",
              "      <td>220</td>\n",
              "      <td>234</td>\n",
              "      <td>150</td>\n",
              "      <td>6172</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581007</th>\n",
              "      <td>2396</td>\n",
              "      <td>153</td>\n",
              "      <td>20</td>\n",
              "      <td>85</td>\n",
              "      <td>17</td>\n",
              "      <td>108</td>\n",
              "      <td>240</td>\n",
              "      <td>237</td>\n",
              "      <td>118</td>\n",
              "      <td>837</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581008</th>\n",
              "      <td>2391</td>\n",
              "      <td>152</td>\n",
              "      <td>19</td>\n",
              "      <td>67</td>\n",
              "      <td>12</td>\n",
              "      <td>95</td>\n",
              "      <td>240</td>\n",
              "      <td>237</td>\n",
              "      <td>119</td>\n",
              "      <td>845</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581009</th>\n",
              "      <td>2386</td>\n",
              "      <td>159</td>\n",
              "      <td>17</td>\n",
              "      <td>60</td>\n",
              "      <td>7</td>\n",
              "      <td>90</td>\n",
              "      <td>236</td>\n",
              "      <td>241</td>\n",
              "      <td>130</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581010</th>\n",
              "      <td>2384</td>\n",
              "      <td>170</td>\n",
              "      <td>15</td>\n",
              "      <td>60</td>\n",
              "      <td>5</td>\n",
              "      <td>90</td>\n",
              "      <td>230</td>\n",
              "      <td>245</td>\n",
              "      <td>143</td>\n",
              "      <td>864</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>581011</th>\n",
              "      <td>2383</td>\n",
              "      <td>165</td>\n",
              "      <td>13</td>\n",
              "      <td>60</td>\n",
              "      <td>4</td>\n",
              "      <td>67</td>\n",
              "      <td>231</td>\n",
              "      <td>244</td>\n",
              "      <td>141</td>\n",
              "      <td>875</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>581012 rows Ã— 55 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Elevation  Aspect  Slope  ...  Soil_Type39  Soil_Type40  Cover_Type\n",
              "0            2596      51      3  ...            0            0           5\n",
              "1            2590      56      2  ...            0            0           5\n",
              "2            2804     139      9  ...            0            0           2\n",
              "3            2785     155     18  ...            0            0           2\n",
              "4            2595      45      2  ...            0            0           5\n",
              "...           ...     ...    ...  ...          ...          ...         ...\n",
              "581007       2396     153     20  ...            0            0           3\n",
              "581008       2391     152     19  ...            0            0           3\n",
              "581009       2386     159     17  ...            0            0           3\n",
              "581010       2384     170     15  ...            0            0           3\n",
              "581011       2383     165     13  ...            0            0           3\n",
              "\n",
              "[581012 rows x 55 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg2gYvwswGek"
      },
      "source": [
        "## Create a dataset class\n",
        "In the next cell we will create a dataset class for our forest cover data. Notice this time the dataset class will directly take a pandas dataframe and then extract the input and labels from it. The data has 55 columns, the first 54 columns contain the cartographic variables used to predict forecast cover type. Notice we convert the data into numpy arrays instead of PyTorch tensors. It is fine for datasets to output numpy arrays since, once we wrap a dataloader around the dataset the dataloader will automatically convert the numpy arrays into PyTorch tensors.\n",
        "\n",
        "You will need to do some work to complete the dataset class below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iomKGo5WelaO"
      },
      "source": [
        "# Import the base class\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Subclassing in Python just requires adding the class name in parentheses\n",
        "class CovDataset(Dataset):\n",
        "    # The __init__ method is similar to a constructor like you find in other\n",
        "    # languages. \n",
        "    def __init__(self, df):\n",
        "        # We directly take the pandas data frame split the data into the inputs\n",
        "        # and labels.\n",
        "        # The first 54 columns contain the input attributes\n",
        "        # The last column called Cover_type contain the data we want to predict\n",
        "        self.inputs = df[df.columns[:54]].to_numpy().astype(np.float32)\n",
        "        self.labels = df.Cover_Type.to_numpy().astype(np.long)\n",
        "        # We make a deep copy of the inputs and store it as a copy of the original.\n",
        "        # This way when we normalize the data in a future exercise we can make sure\n",
        "        # we always apply the normalization based on the original inputs.\n",
        "        self.original_inputs =  self.inputs.copy()\n",
        "\n",
        "    def __len__(self):\n",
        "        # TODO: Return the length (number of items) in the dataset\n",
        "        return len(cover_type_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # TODO: Store the inputs and labels for the item at index idx in variables\n",
        "        #       input and label\n",
        "        input = self.inputs[idx]\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "       \n",
        "\n",
        "        return input, label\n",
        "\n",
        "    # TODO: there will be instructions later for you to add a normalization\n",
        "    #       function here. Remember you want to do the normalization from the\n",
        "    #       original_inputs instead of inputs.\n",
        "\n",
        "    def normalize_data(self, mean, std):\n",
        "      self.inputs = ((self.original_inputs - mean)/std).astype(np.float32)  \n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfcSj7Mdxwt4"
      },
      "source": [
        "## Create train, validation and test dataset splits and dataloaders\n",
        "\n",
        "Notice the difference between this labs data loading code versus lab2a. The main difference is that we created a dataset class in the previous cell and passed the dataframe into it. So all the messy extraction of input data and labels are done in the dataset class. I think in general writing a dataset class is a more elegant way to code dataloading. So I encourage you to do that in the future as well.\n",
        "\n",
        "You will notice the this dataset is quite large.\n",
        "\n",
        "Please follow the instructions below to complete the code for creating the dataset object and then spliting it into train, validation and test splits. Then creating a *dataloader* for each dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-O1HG9shUo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83628b1b-1b2d-41d2-f41c-ceec9fe6f56d"
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset, TensorDataset, random_split\n",
        "\n",
        "# The percentages for each partition\n",
        "TRAIN_SPLIT = 0.8\n",
        "VAL_SPLIT = 0.1\n",
        "TEST_SPLIT = 0.1\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Ensure that the splits add to 100%\n",
        "assert TRAIN_SPLIT + VAL_SPLIT + TEST_SPLIT == 1\n",
        "\n",
        "# TODO : create the forecast cover dataset (CovDataset) object using the cover_type_df\n",
        "#        dataframe.\n",
        "entirecoverDataSet = CovDataset(cover_type_df)\n",
        "\n",
        "\n",
        "# Calculate the number of examples in each partition\n",
        "train_size = int(TRAIN_SPLIT * len(entirecoverDataSet))\n",
        "val_size = int(VAL_SPLIT * len(entirecoverDataSet))\n",
        "test_size = len(entirecoverDataSet) - train_size - val_size\n",
        "\n",
        "print(\"Train examples:     \", train_size)\n",
        "print(\"Validation examples:\", val_size)\n",
        "print(\"Test examples:      \", test_size)\n",
        "\n",
        "\n",
        "#TODO Just like you did in lab2a please use the random_split function to \n",
        "#     break entirecoverDataSet into train_dataset, val_dataset, test_dataset\n",
        "# train_dataset, val_dataset, test_dataset = \n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "  entirecoverDataSet, [train_size, val_size, test_size])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#TODO Just like you did in lab2a please create the train_loader, val_loader\n",
        "#     and test_loader using their corresponding datasets.\n",
        "#     Please do random shuffling for the train_loader, do not do random shuffle\n",
        "#     for the other two data loaders\n",
        "\n",
        "train_loader = DataLoader(train_dataset,BATCH_SIZE, shuffle = True)\n",
        "val_loader = DataLoader(val_dataset,BATCH_SIZE, shuffle = False)\n",
        "test_loader = DataLoader(test_dataset,BATCH_SIZE, shuffle = False)\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train examples:      464809\n",
            "Validation examples: 58101\n",
            "Test examples:       58102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfcp-KX0lgs4"
      },
      "source": [
        "Lets take a look at the first element of the training dataset that we created. You should see a tuple where the first element contains a 1D array with 54 elements and the second element stores the output label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCLUadTukD2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66863b69-66d4-4904-e0bc-7805f1a58240"
      },
      "source": [
        "print(train_dataset[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([3.271e+03, 3.800e+01, 2.400e+01, 2.400e+02, 1.200e+01, 2.670e+03,\n",
            "       2.120e+02, 1.810e+02, 9.200e+01, 1.403e+03, 0.000e+00, 0.000e+00,\n",
            "       1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "       0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
            "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
            "      dtype=float32), 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4lAnCZr5q1M"
      },
      "source": [
        "## MLP model\n",
        "\n",
        "In the cell below finish the definition of a MLP model that will be used in the training loop. Notice we have already specified the default input and output size for the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU_e7ShVl9vw"
      },
      "source": [
        "\n",
        "# Custom models need to subclass nn.Module\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self,\n",
        "                 device,\n",
        "                 input_size=54, # default to 54\n",
        "                 output_size=8 # default to the number of classes\n",
        "                 ):\n",
        "        super().__init__()\n",
        "\n",
        "        # Write the classifier layers here.\n",
        "        self.seq = nn.Sequential(\n",
        "            \n",
        "            ## TODO: add the following layers\n",
        "            #        Linear layer that outputs 64 neurons\n",
        "            nn.Linear(input_size,64),\n",
        "            #        ReLU\n",
        "            nn.ReLU(),\n",
        "            #        Linear layer that outputs 64 neurons\n",
        "            nn.Linear(64,64),\n",
        "            #        ReLU\n",
        "            nn.ReLU(),\n",
        "            #        Linear layer that outputs output_size neurons\n",
        "            nn.Linear(64,output_size)\n",
        "           \n",
        "        )\n",
        "        # Transfer the model weights to the GPU\n",
        "        self.to(device)\n",
        "    \n",
        "    # The forward method takes input values and returns predictions. We just need\n",
        "    # to pass the inputs through the layers we defined in __init__\n",
        "    def forward(self, x):\n",
        "        return self.seq(x)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9zQhj8H6bIj"
      },
      "source": [
        "## Training loop\n",
        "To keep things simple I have just copied the training loop used in lab 2b here to do the training. Note we are not using the validation dataset in order to keep the training code short. I have set the optimizer to the Adam optimizer with initial learning rate of 0.001.\n",
        "\n",
        "Lets train the model and see what happens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vmRY2Q3ncXk"
      },
      "source": [
        "def compute_accuracy(predictions, targets):\n",
        "    # Find the index with the highest predicted value - this is the predicted digit\n",
        "    predictions = predictions.argmax(1)\n",
        "    # Count the number of predictions that match the target\n",
        "    correct = (predictions == targets).sum().item()\n",
        "    # Compute the accuracy as the percentage correctly predicted\n",
        "    acc = correct / len(targets)\n",
        "    return acc"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CGeH6MXnmda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423,
          "referenced_widgets": [
            "871004aa13eb4b05a56bcde07a5663bc",
            "ab359fda44de4eafa3108db68d21df26",
            "342e858ed43344519db30b493181e2d9",
            "88a0cba8150845d0a9681a592b6d5ee2",
            "be8559d8a9f6495ea025de683beda94f",
            "948730672fc24d369e28b4321c761fa7",
            "f966fbf0b2894f31a075b6eab7f0447e",
            "5c3bc724496f469eabb51889853c4905"
          ]
        },
        "outputId": "86031f44-f819-436b-a72b-e88d73641012"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = MLP(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# The number of times we loop over the entire dataset\n",
        "total_epochs = 10\n",
        "for epoch in tqdm(range(total_epochs)): \n",
        "    epoch_train_accuracy = []\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)   \n",
        "        accuracy = compute_accuracy(outputs, labels)\n",
        "        epoch_train_accuracy.append(accuracy)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print('epoch: %d loss: %.3f' % (epoch + 1, running_loss / len(train_loader)))\n",
        "    print('epoch: %d accuracy: %.3f' % (epoch + 1, np.mean(epoch_train_accuracy)))\n",
        "print('Finished Training')\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "871004aa13eb4b05a56bcde07a5663bc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 loss: 0.976\n",
            "epoch: 1 accuracy: 0.645\n",
            "epoch: 2 loss: 0.656\n",
            "epoch: 2 accuracy: 0.717\n",
            "epoch: 3 loss: 0.609\n",
            "epoch: 3 accuracy: 0.737\n",
            "epoch: 4 loss: 0.583\n",
            "epoch: 4 accuracy: 0.750\n",
            "epoch: 5 loss: 0.566\n",
            "epoch: 5 accuracy: 0.757\n",
            "epoch: 6 loss: 0.555\n",
            "epoch: 6 accuracy: 0.762\n",
            "epoch: 7 loss: 0.547\n",
            "epoch: 7 accuracy: 0.766\n",
            "epoch: 8 loss: 0.540\n",
            "epoch: 8 accuracy: 0.769\n",
            "epoch: 9 loss: 0.533\n",
            "epoch: 9 accuracy: 0.773\n",
            "epoch: 10 loss: 0.527\n",
            "epoch: 10 accuracy: 0.775\n",
            "\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9d-l6Oq7Evm"
      },
      "source": [
        "If everything goes according to plan you will notice that the training accuracy is around 77%. This is not that high considering other people can get 100% accuracy. Lets see what happens when we try it on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-DfqSIEqi1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5946efb-8425-4216-f0d0-9f953f281ab1"
      },
      "source": [
        "running_loss = 0.0\n",
        "total_test_accuracy = []\n",
        "\n",
        "for i, data in enumerate(test_loader, 0):\n",
        "   inputs, labels = data\n",
        "   inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "   model.eval()\n",
        "   with torch.no_grad():\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    running_loss += loss.item()\n",
        "    accuracy = compute_accuracy(outputs, labels)\n",
        "    total_test_accuracy.append(accuracy) \n",
        "\n",
        "print(\"test loss: \", running_loss/len(test_loader))\n",
        "print('test accuracy: ', np.mean(total_test_accuracy))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test loss:  0.516637130882509\n",
            "test accuracy:  0.7759664606787404\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB-AGEhU7lkK"
      },
      "source": [
        "## Normalizing the data\n",
        "The test dataset also just reports accuracy of around 77%. Lets see if we can significantly improve the results using normalization.\n",
        "\n",
        "The normalization we want to do is called the [Standard score](https://en.wikipedia.org/wiki/Standard_score#Calculation) or z-score. So you subtract the mean and divide by the standard deviation. So this means we need to compute the mean and standard deviation of every column of the data resulting in 54 means and 54 standard deviations. \n",
        "\n",
        "Doing this normalization to each column will make the values in each column have similar range of values and make them small and centered around zero. This will make the job of training the neural network much easier since the weights of the linear layer can have similar range of values since the input across the different input features have similar magnitudes.\n",
        "\n",
        "The mean and standard deviation that we compute must be from the training dataset since in theory we do not have the statistics of the validation and test sets when training our model. Since the model is trained on the normalized data from the training set, it means when we perform validation and testing we also need to normalize the data based on the mean and standard deviation computed in the training dataset.\n",
        "\n",
        "In the code below we first extract the numpy array containing the input data from the training dataset. It is up to you to write the code to compute the mean and standard deviation for each column of the data.\n",
        "\n",
        "If you have done it correctly the data should be a 1D array with 54 elements.\n",
        "\n",
        "We then call a normalize_data function on the entire dataset to normalize the train, validation and test datasets using the mean and standard deviation we just computed. We can do this by just normalizing the input data in the  <font color=red> entirecoverDataSet </font> object since all the other splits all use this dataset by just index different elements of it.\n",
        "\n",
        "You need to go back to the <font color=red> CovDataset </font> class and add a function called <font color=red> normalize_data </font> which will normalize the input data member by subtracting the mean of the training data and dividing by the standard deviation. In the function please compute the normalized input based on the <font color=red original_inputs> instead of <font color=red inputs>. The reason for this is if you accidently call normalize twice, you don't want to the normalization to compound on each other. \n",
        "\n",
        "Once you have added the normalization function you will need to execute the \"Create train, validation and test dataset splits and dataloaders\" cell again to ensure the new updated definition of the <font color=red> CovDataset </font> class is used by the dataloaders. Then you will need to normalize the data by executing the next cell.\n",
        "\n",
        "Once you have normalized the data, please go back to the training loop and execute it again. See how much higher the training and test accuracy goes. You should see a very significant increase in the accuracy (around 10% higher accuracy).\n",
        "\n",
        "If you have time at the end of the lab. Feel free to come up with better models and also try different optimization parameter values to see if you can push the accuracy even higher.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK-JE8AFJ8EM"
      },
      "source": [
        "# Here we extract the input data of the training dataset into a\n",
        "# numpy array called train_inputs.\n",
        "train_inputs = entirecoverDataSet.inputs[train_dataset.indices]\n",
        "\n",
        "# TODO : write code to extract the mean and standard deviation for each column \n",
        "#        of the data and store them in the following variables.\n",
        "train_inputs_means = train_inputs.mean(axis=0)\n",
        "train_column_stds =  train_inputs.std(axis=0)\n",
        "\n",
        "\n",
        "# We call a normalize_data function on the entire data set.\n",
        "# This normalizes all the input data for the train, validation and test splits\n",
        "# in one go. \n",
        "# TODO: Please go to the CovDataset class and add a function called\n",
        "#       normalize_data which normalizes the input by subtracting the mean\n",
        "#       and dividing by the standard deviation from the original_input.\n",
        "entirecoverDataSet.normalize_data(train_inputs_means, train_column_stds)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqLNhhWUUKYQ"
      },
      "source": [
        "## Learning Rate Adjustments\n",
        "\n",
        "In the past, we've mentioned the effects of a poor choice of learning rate, and we'll now look at a practical example.\n",
        "\n",
        "To demonstrate this, we'll build a simple image dataset consisting of white squares and rectangles on a black background, with the task of classifying them as either squares or rectangles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlh4uTUNeonM"
      },
      "source": [
        "### Preparation\n",
        "\n",
        "As before, the dataset has been implemented you. Feel free to read through it - although the implementation isn't particularly important.\n",
        "\n",
        "Each example in the dataset consists of a white rectangle of a randomly chosen width and height, with a label of `1` if it's a square and `0` if it's a rectangle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVzxCZsVS32B"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ToyImageDataset(Dataset):\n",
        "    def __init__(self, num_examples):\n",
        "        super().__init__()\n",
        "        height, width = 12, 12\n",
        "        self.images, self.labels = self.gen_examples(num_examples, height, width)\n",
        "\n",
        "    def gen_examples(self, num_examples, height, width):\n",
        "        # Rectangles can be at most half the width or height of the image\n",
        "        max_height, max_width = height // 2, width // 2\n",
        "\n",
        "        # Initialise a tensor of zeros to fill in with rectangles\n",
        "        images = torch.zeros((num_examples, 1, height, width), dtype=torch.float32)\n",
        "\n",
        "        # Randomly generate the top-left corner of each rectangle\n",
        "        tops = torch.randint(0, height - 1, (num_examples,))\n",
        "        lefts = torch.randint(0, width - 1, (num_examples,))\n",
        "        # Randomly generate the heights and widths\n",
        "        heights = torch.randint(1, max_height + 1, (num_examples,))\n",
        "        widths = torch.randint(1, max_width + 1, (num_examples,))\n",
        "        # Calculate the bottom-right corner of each rectangle, being sure to not\n",
        "        # go beyond the image edge\n",
        "        bottoms = torch.clamp(tops + heights, 0, height)\n",
        "        rights = torch.clamp(lefts + widths, 0, width)\n",
        "\n",
        "        # Colour in the rectangles\n",
        "        for i, (t, l, b, r) in enumerate(zip(tops, lefts, bottoms, rights)):\n",
        "            images[i, :, t:b, l:r] = 1\n",
        "\n",
        "        # Squares are rectangles with equal widths and heights\n",
        "        labels = (heights == widths).type(torch.float32).unsqueeze(-1)\n",
        "        return images, labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.labels[idx]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aojIUOth0lL"
      },
      "source": [
        "Run the next cell to create a couple of datasets and dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpMhiYA2MFZY"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "torch.manual_seed(42)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataset = ToyImageDataset(900)\n",
        "test_dataset = ToyImageDataset(100)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSr5aNQRh3rJ"
      },
      "source": [
        "Let's take a look at some examples from the training dataset. You'll notice that there are very few square examples - we'll return to this later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVwhfIITcePL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "7b66ddbd-e6b1-4143-9dac-a7a8003f0bf0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i, (image, label) in enumerate(train_dataset):\n",
        "    if i == 24: break\n",
        "    plt.subplot(4, 6, i+1)\n",
        "    plt.imshow(image[0], cmap='gray', interpolation='nearest')\n",
        "    plt.axis('off')\n",
        "    plt.title('Square' if label else 'Rect')\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 24 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkU-XqXgiLhO"
      },
      "source": [
        "The CNN for this task is implemented below - note that as we're doing *binary* classification (between two classes), we output a single value. A value nearer to `0` is a prediction of class `0` and a value nearer to `1` is a predictions of class `1`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa7-MFw3gs7n"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# This Printer class is just used to print out the shape of the tensor before\n",
        "# putting it into the linear layer so we know what is the input size for the linear\n",
        "# layer.\n",
        "class Printer(nn.Module):\n",
        "    def forward(self, x):\n",
        "        print(x.shape)\n",
        "        return x\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, device):\n",
        "        super().__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "            nn.Conv2d(1, 2, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(2, 4, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(4, 4, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(4, 4, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            # Printer(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(36, 1)\n",
        "        )\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.seq(x)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziZ8ow_CN-bu"
      },
      "source": [
        "This function plots training and testing values (we'll use it to graph the loss and accuracy)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMWyjXNfN9nA"
      },
      "source": [
        "def plot(title, train_vals, test_vals):\n",
        "    plt.plot(range(len(train_vals)), train_vals, label='Train')\n",
        "    plt.plot(range(len(test_vals)), test_vals, label='Test')\n",
        "    plt.legend()\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_2rp2ehSW3F"
      },
      "source": [
        "def compute_accuracy(predictions, targets):\n",
        "    # We will use a threshold of 0.5 to decide that the prediction is a square.\n",
        "    # In practice sometimes it is good to change this threshold.\n",
        "    predictions = torch.where(predictions >=0.5, 1, 0)\n",
        "    # Count the number of predictions that match the target\n",
        "    correct = (predictions == targets).sum().item()\n",
        "    # Compute the accuracy as the percentage correctly predicted\n",
        "    return correct / len(targets)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhvAMyP9Ngm5"
      },
      "source": [
        "Here we have a function to perform training and testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr2sTAJMENBX"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def train_and_test(model, train_loader, test_loader, loss_func, optimiser, num_epochs, acc_func=None):\n",
        "    train_losses, test_losses = [], []\n",
        "    train_accs, test_accs = [], []\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        sum_loss, sum_acc = 0, 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimiser.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_func(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimiser.step()\n",
        "            sum_loss += loss.item()\n",
        "            if acc_func: sum_acc += acc_func(outputs, labels)\n",
        "        train_losses.append(sum_loss / len(train_loader))\n",
        "        train_accs.append(sum_acc / len(train_loader))\n",
        "\n",
        "        sum_loss, sum_acc = 0, 0\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_func(outputs, labels)\n",
        "            sum_loss += loss.item()\n",
        "            if acc_func: sum_acc += acc_func(outputs, labels)\n",
        "        test_losses.append(sum_loss / len(test_loader))\n",
        "        test_accs.append(sum_acc / len(test_loader))\n",
        "\n",
        "    return train_losses, test_losses, train_accs, test_accs"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apE5PWd2iqzz"
      },
      "source": [
        "### Train the Model\n",
        "\n",
        "We now call the training and plotting functions to train and view the training and testing accuracy curves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz4wxeq7fMOB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398,
          "referenced_widgets": [
            "f352653ec508406a80c262f42ea05e23",
            "da9934e121a248f5933778b6dd0a31d9",
            "7d0f6952c2014e73a1a855acad2ba0ee",
            "ac4a02d7ab0c4bc0a6f9399ac5c55b70",
            "525e7fe7282747a998fa09cce6cb6f22",
            "cb78c41f23cd4e6e88da4d86b784a547",
            "a7c49cd973f54f5aae969fd86d9889d3",
            "3b40567def634a4d83cbcd46f292d6d5"
          ]
        },
        "outputId": "9e9b2f29-8f09-4b95-fd7d-59064fcf5643"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model = ConvNet(device)\n",
        "# Note this Binary Cross Entropy Loss expects the input to be logits.\n",
        "# This means you should not have a sigmoid at the end your model, since\n",
        "# the sigmoid is automatically put there for you.\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n",
        "\n",
        "# TODO: First try the code. Then adjust the learning rate (lr) to something more reasonable like 1e-3.\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "train_losses, test_losses, train_accs, test_accs = train_and_test(model,\n",
        "                                                  train_loader,\n",
        "                                                  test_loader,\n",
        "                                                  loss_func,\n",
        "                                                  optimiser,\n",
        "                                                  num_epochs= 1000,\n",
        "                                                  acc_func=compute_accuracy)\n",
        "\n",
        "plot(\"Accuracy\", train_accs, test_accs)\n",
        "\n",
        "print(\"train loss: \", train_losses[-1])\n",
        "print(\"train accuracy: \", train_accs[-1])\n",
        "print(\"test loss: \", test_losses[-1])\n",
        "print(\"test accuracy: \", test_accs[-1])\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f352653ec508406a80c262f42ea05e23",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "train loss:  0.14736939718325934\n",
            "train accuracy:  0.9208333333333333\n",
            "test loss:  0.7614786252379417\n",
            "test accuracy:  0.8350694444444444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkcFKl5Oiwwa"
      },
      "source": [
        "### Fix the Problem\n",
        "\n",
        "That train acurracy is very unstable! Also the test accuracy just stays flat  This sort of accuracy curve is usually indicative of a badly-selected learning rate. The learning rate above is set to `1`, which would be considered a very high learning rate.\n",
        "\n",
        "\n",
        "<font color='red'>Adjust the learning rate and train the model again. Try something smaller like 1e-3.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKKQl5-7Wv1s"
      },
      "source": [
        "### Detecting the class imbalance problem\n",
        "\n",
        "The test accuracy looks weird, it starts at 80% and then only moves to around 85%. Lets now look a bit further under the hood. By looking at the distribution of rectangle and square examples in the train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vwj35PkWh3QJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d092bd9e-e96f-423e-b5ac-d730e601d642"
      },
      "source": [
        "train_square_proportion = len(torch.nonzero(train_dataset.labels)) / len(train_dataset.labels)\n",
        "train_rect_proportion = 1 - train_square_proportion\n",
        "\n",
        "test_square_proportion = len(torch.nonzero(test_dataset.labels)) / len(test_dataset.labels)\n",
        "test_rect_proportion = 1 - test_square_proportion\n",
        "\n",
        "print(\"Train data - Rectangle proportion:\", \"{:.3f}\".format(train_rect_proportion), \"Square proportion:\", \"{:.3f}\".format(1- train_rect_proportion))\n",
        "print(\"Test data - Rectangle proportion:\", \"{:.3f}\".format(test_rect_proportion), \"Square proportion:\", \"{:.3f}\".format(1- test_rect_proportion))\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data - Rectangle proportion: 0.843 Square proportion: 0.157\n",
            "Test data - Rectangle proportion: 0.800 Square proportion: 0.200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSHRyol9kBzT"
      },
      "source": [
        "It turns out the reason the model initially got 80% accuracy was because it just always predicted rectangle no matter what input it got. Since there was 80% rectangles in the test set it got the answer correct 80% of the time. Later the model was able to sometimes predict Squares but still not often enough hence it did not move much higher than 80%. There are so many more examples of rectangles compared to squares so during backprop most of the gradients try to steer the model towards predicting rectangles. \n",
        "\n",
        "Lets take a look at the confusion matrix on the trained model to confirm our intuition that the model is predicting too many rectangles instead of squares.\n",
        "\n",
        "The first cell below contains the implementation of function used draw the confusion matrix which I copied from a file called plotcm.py from scikit-learn.org.\n",
        "\n",
        "The second cell contains the code that uses the plot_confusion_matrix function defined in the previous cell to draw our confusion matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msP85Q3Il22K"
      },
      "source": [
        "Confusion matrix function definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOod1ZyalKaQ"
      },
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6YSuw50l-_E"
      },
      "source": [
        "Our code to draw the confusion matrix of our model results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVOb7FhBXBoc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "a4faf98e-b2b7-45d6-9e4f-361a1a5e23dc"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "# Gather targets and predictions for the whole test set\n",
        "targets, predictions = [], []\n",
        "for inputs, labels in test_loader:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    targets.extend(labels.detach().cpu().numpy())\n",
        "    predictions.extend(outputs.detach().cpu().numpy())\n",
        "targets = np.reshape(targets, -1).astype(int)\n",
        "predictions = np.reshape(predictions, -1)\n",
        "# we assign any prediction above or equal to 0.5 as 1 for square.\n",
        "predictions = np.where(predictions >= 0.5, 1, 0)\n",
        "cm = confusion_matrix(targets, predictions)\n",
        "plot_confusion_matrix(cm, [\"rectangle\", \"square\"])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[73  7]\n",
            " [13  7]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xme8Ga6AnDOY"
      },
      "source": [
        "The bottom left and top right cells are where the predictions are different from the true labels. This result looks not too bad. It seems we are making a bit more mistakes predictions when the ground truth is squares (bottom left cell) than when the ground truth is rectangles (top right cell). But the problem looks much more obvious when we look at the next cell where we plot the normalized confusion matrix. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIEO_AAsm6lw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "24d0b1c1-b956-47f6-9284-e49b87299714"
      },
      "source": [
        "# In this cell we will draw the normalized confusion matrix\n",
        "plot_confusion_matrix(cm, [\"rectangle\", \"square\"], normalize = True)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalized confusion matrix\n",
            "[[0.9125 0.0875]\n",
            " [0.65   0.35  ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TZ4VoxknllT"
      },
      "source": [
        "<font color=red> This result shows us a really big problem! </font> Look at the bottom left cell. It says that we wrongly predicted about 65% (you may get something between 50% to 75%) of the images that contained squares. So this really shows us our result is actually much worse than the around 85% accuracy reported earlier. We need to use a different metric that better reflects our true performance in terms of both predicting rectangles and squares. So a fairer metric that treats rectangles and squares equally.\n",
        "\n",
        "So lets turn to the unweighted average recall (UAR) metric which we discussed in lecture 4 to help us out. The UAR metric essentially assigns equal importance to correctly predicting rectangles and squares when they are present in the image. \n",
        "\n",
        "The next cell computes the UAR performance of our model on the test set.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCRilq5xZ86o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89a5e203-1e0e-4b0e-981c-a12f7449d2f1"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# Gather targets and predictions for the whole test set\n",
        "targets, predictions = [], []\n",
        "for inputs, labels in test_loader:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    targets.extend(labels.detach().cpu().numpy())\n",
        "    predictions.extend(outputs.detach().cpu().numpy())\n",
        "targets = np.reshape(targets, -1).astype(int)\n",
        "predictions = np.reshape(predictions, -1)\n",
        "# we assign any prediction above or equal to 0.5 as 1 for square.\n",
        "predictions = np.where(predictions >= 0.5, 1, 0)\n",
        "\n",
        "recall_rect = recall_score(targets, predictions, average='binary', pos_label=0)\n",
        "print(\"recall for rectangles = \", recall_rect)\n",
        "recall_square = recall_score(targets, predictions, average='binary', pos_label=1)\n",
        "print(\"recall for squares = \", recall_square)\n",
        "UAR = (recall_rect + recall_square) / 2\n",
        "print(\"UAR = \", UAR)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recall for rectangles =  0.9125\n",
            "recall for squares =  0.35\n",
            "UAR =  0.63125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g6nUfRic0tQ"
      },
      "source": [
        "Notice the recall for squares is much lower than the recall for the rectangles. The UAR (the average of the two recalls) is about 0.66 (the number you get maybe different should be mostly similar). Lets try some techniques to help balance the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDcaK4vjwNMb"
      },
      "source": [
        "### Fix the Problem\n",
        "\n",
        "Now that we have a method for truly measuring the model's performance, we should fix the class imbalance.\n",
        "\n",
        "The simplest technique for correcting this is to change the proportion of examples that we present to the model. If we randomly select examples without any consideration for the imbalance, we will show the model 80% rectangles and 20% squares on average - we would like to instead show it 50% of each.\n",
        "\n",
        "PyTorch provides a class [WeightedRandomSampler](https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler) to help us with this. Instead of giving each example the same chance of being selected from the dataset, we can weight their selection probability - so an example with a weight of `2` is twice as likely to be selected as an example with a weight of `1`.\n",
        "\n",
        "To undo the imbalance, we choose the weights based on the proportion of examples. So if classes `A` and `B` have a 9:1 ratio in a dataset, we would need to weight class `A` by a factor of 1, and class `B` by a factor of 9.\n",
        "\n",
        "To compute this directly, the weights of a class should be $1 - p$, where $p$ is the proportion of that class in the dataset. We have already computed the proportions for each of our two classes, so we can use this equation to compute their appropriate weights.\n",
        "\n",
        "<font color='red'>In the next cell, compute the sampling weights for the two classes.</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uml4iiS0vKJs"
      },
      "source": [
        "# TODO: Compute the square and rectangle weights using the above equation\n",
        "square_weight = 1 - train_square_proportion\n",
        "rect_weight = 1 - train_rect_proportion\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuwDCend5b20"
      },
      "source": [
        "The [WeightedRandomSampler](https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler) class requires a weight for each example in the dataset, so we will iterate over every label in the training dataset and build a list of the correct weight. Run the next cell to do so."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHULDTTE5Tx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d4d4c5d-0cf8-4fe2-f744-963e35683573"
      },
      "source": [
        "weights = [square_weight if l == 1 else rect_weight for l in train_dataset.labels]\n",
        "\n",
        "# Print out the first 5 weights\n",
        "print(weights[:5])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.8433333333333333, 0.15666666666666673, 0.15666666666666673, 0.15666666666666673, 0.15666666666666673]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJzdTi5353-3"
      },
      "source": [
        "All that's left now is to initialise the sampler and use it to create a new train dataloader.\n",
        "\n",
        "In the next cell, initialise a <font color='red'>torch.utils.data.sampler.WeightedRandomSampler</font> by providing the weights list and the length of the train dataset as arguments.\n",
        "\n",
        "If you code is correct the number of squares should be roughly half of the number of examples in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT_YxAwL52wW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0499c876-c52e-4505-ad1b-525dc00f8f60"
      },
      "source": [
        "# TODO: Initialise a WeightedRandomSampler\n",
        "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(train_dataset))\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler)\n",
        "\n",
        "total = 0\n",
        "for inputs, labels in train_loader:\n",
        "  total = total + labels.detach().cpu().numpy().sum()\n",
        "\n",
        "print(\"number of squares: \", total)\n",
        "print(\"total number of training examples:\", len(train_dataset))\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of squares:  457.0\n",
            "total number of training examples: 900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIAq3HBQ64lM"
      },
      "source": [
        "Once you've completed the above cell, return to the \"Train the Model\" section to try it out.\n",
        "\n",
        "Once training has completed, run the cell that computes the UAR. If all goes well, the square recall should and the UAR should be higher than before as well. This is because we are showing the model balanced porportions of squares and rectangles throughout training. However, don't be too stressed it the square recall and UAR does not go higher. We have noticed there is some randomness in the results due to the small number of different square examples used during training. You may need to run again to see the benefits. The majority of the times when you rerun the training with the balanced sampler the results should be better. But you might get unlucky once or twice.\n",
        "\n",
        "Although this method is very useful for handling class imbalance, it can't perform magic - there is a limit to its efficacy. So your UAR will still not be that high. There are other ways to handle skewed distributions. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He9ky8tsqTDp"
      },
      "source": [
        "## Use a weighted Loss Function to Address Skew\n",
        "\n",
        "There is another way to address skewed training distributions. We can increase the size of the gradients going back when training examples of the minority class. This way we can train in a more balanced way without the need to adjust the sampling rate of the two classes. \n",
        "\n",
        "It turns out the loss that we are currently using called <font color= red> torch.nn.BCEWithLogitsLoss</font> already has a parameter called <font color= red>pos_weight</font> that we can use to adjust the weighting we assign to the positive class (the class with label 1).\n",
        "\n",
        "Take a look at this documentation to work out how you can modify the loss so the minor class gets more weight :\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html\n",
        "\n",
        "It is up to you to decide what weight to use and how to code it. Good luck! You should be able to get better results than using the balanced sampling method.\n",
        "Please note you need to go back to the old standard dataloader, not the one you modified to use the balanced sampler. So please execute the code in the next cell to reset the dataloader for the training set to the old dataloader.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re7PcLDItF8G"
      },
      "source": [
        "# Run this code to reset the dataloader so we do not use the weighted sampler\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wVkrtxMpuK4"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "As a challenge try to change the model, learning rate, optimization algorithms, increase the number of training epochs, play around with the loss weight, etc. to see if you can improve the UAR score, and let us know the best UAR you can get! Note that due to the small number of square training examples, you might find a lot of random fluctuation in your test accuracy which makes optimization very hard, so don't spend too much time on this. You should keep a record of what you tried in an excel spreadsheet like we did in lab 3. This is a really important habit to form since people tend to forget what they tried after some time.\n",
        "\n",
        "You can also play around and see if you can optimize the accuracy of the forest cover classification problem as well. This is a much larger dataset and so produces more stable results. Also for fun you might want to see if the class distribution of this dataset is also imbalanced. If so, you want to do something about that too!\n",
        "\n",
        "Good luck! By the end of this lab you will have practiced optimizing many different neural network models across the last few labs! You are starting to turn into a neural network optimizer pro!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dsoZL-L7xwe"
      },
      "source": [
        "That's it for this lab - nice work! Hopefully you've learnt something about debugging neural networks. Although there are many ways in which a neural network can fail, we've now seen three of the most common problems."
      ]
    }
  ]
}